---
title: "Final Project"
author: "Sienna Wang, Hengyi Xing"
date: "2024-11-03"
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
output:
  echo: false
  eval: false
---

```{python}
import pandas as pd
import altair as alt
alt.renderers.enable("png")
import geopandas as gpd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS
```

```{python}
# Read in the GTD dataset
path = '/Users/hengyix/Documents/GitHub/DAP2-FINAL/data/'
file_gtd = 'globalterrorismdb.csv'
df_gtd = pd.read_csv(path+file_gtd)
```

```{python}
# Data cleaning for the two maps
gtd_count = gtd_clean.groupby('country_txt').agg(
    attack_count=('country_txt', 'size'),
    casualties=('nhurt', 'sum')
).reset_index()
gtd_map = gtd_count.copy()

# Read in the shapefile
file_shape = (
    'world-administrative-boundaries/world-administrative-boundaries.shp')
world_shapefile = gpd.read_file(path+file_shape)
world_shapefile = world_shapefile[['name', 'geometry']]

# Match the countries with the shapefile
# Match the format according to the shapefile
gtd_map.loc[gtd_map['country_txt'] == 'Serbia', 'attack_count'] += 162
gtd_map.loc[gtd_map['country_txt'] == 'Serbia', 'attack_count'] += 11
gtd_map.loc[gtd_map['country_txt'] == 'Serbia', 'casualties'] += 279
gtd_map.loc[gtd_map['country_txt'] == 'Serbia', 'casualties'] += 8
gtd_map.loc[gtd_map['country_txt'] == 'Yugoslavia', 'attack_count'] += 106
gtd_map.loc[gtd_map['country_txt'] == 'Yugoslavia', 'casualties'] += 91

# Adjust country names in the shapefile to handle NAs manually
name_dict_map = {'Bosnia & Herzegovina': 'Bosnia-Herzegovina',
             'Brunei Darussalam': 'Brunei',
             'Timor-Leste': 'East Timor',
             'Iran (Islamic Republic of)': 'Iran',
             "CÃ´te d'Ivoire": 'Ivory Coast',
             "Lao People's Democratic Republic": 'Laos',
             'Libyan Arab Jamahiriya': 'Libya',
             'The former Yugoslav Republic of Macedonia': 'Yugoslavia',
             'Moldova, Republic of': 'Moldova',
             'Congo': 'Republic of the Congo',
             'Russian Federation': 'Russia',
             'Slovakia': 'Slovak Republic',
             'Republic of Korea': 'South Korea',
             'Saint Lucia': 'St. Lucia',
             'Syrian Arab Republic': 'Syria',
             'United Republic of Tanzania': 'Tanzania',
             'U.K. of Great Britain and Northern Ireland': 'United Kingdom',
             'United States of America': 'United States',
             'West Bank': 'West Bank and Gaza Strip',
             }
world_shapefile['name'] = world_shapefile['name'].map(
    name_dict_map).fillna(world_shapefile['name'])

gtd_map = pd.merge(world_shapefile, gtd_map,
                   left_on='name', right_on='country_txt', how='left').fillna(0)
```

```{python}
fig, ax = plt.subplots(1, 1, figsize=(10, 5))
gtd_map.plot(column='attack_count', ax=ax, legend=True,
         legend_kwds={
             'label': "Attack Count by Country",
             'orientation': "vertical",
             'shrink': 0.5,      
             'aspect': 20,       
             'pad': 0.01,       
             'anchor': (0.2, 0.5)
         },
         cmap='Reds')  


ax.set_facecolor('lightblue')
ax.set_xticks([]) 
ax.set_yticks([]) 
plt.title('Global Attack Count Heatmap')
plt.show()
```

```{python}
fig, ax = plt.subplots(1, 1, figsize=(10, 5))
gtd_map.plot(column='casualties', ax=ax, legend=True,
         legend_kwds={
             'label': "Casualty by Country",
             'orientation': "vertical",
             'shrink': 0.5,      
             'aspect': 20,       
             'pad': 0.01,       
             'anchor': (0.2, 0.5)
         },
         cmap='Reds')  


ax.set_facecolor('lightblue')
ax.set_xticks([]) 
ax.set_yticks([]) 
plt.title('Global Attack Casualty Heatmap')
plt.show()
```

```{python}
file_democracy = 'p5v2018.csv'
df_democracy = pd.read_csv(path+file_democracy)
# Clean the dataset
df_democracy = df_democracy.loc[df_democracy['year'] > 1999, [
    'country', 'year', 'polity']]
# Calculate the average democracy score for each country
country_score = df_democracy.groupby(
    'country')['polity'].mean().reset_index(name='avg_score')


# Moderate the country names in country_score to do the matching
# Erase NAs maually
name_dict_demo = {
    'Bosnia': 'Bosnia-Herzegovina',
    'Congo Kinshasa': 'Democratic Republic of the Congo',
    'Dominican Republic': 'Dominica',
    'Timor Leste': 'East Timor',
    'Myanmar (Burma)': 'Myanmar',
    'Congo-Brazzaville': 'Republic of the Congo',
    'Serbia and Montenegro': 'Serbia-Montenegro',
    'Korea South': 'South Korea'
}
country_score['country'] = country_score['country'].map(
    name_dict_demo).fillna(country_score['country'])
gtd_score = pd.merge(gtd_count, country_score, how='inner',
                     left_on='country_txt', right_on='country')
# Add HK count to China count
gtd_score.loc[gtd_score['country_txt'] == 'China', 'attack_count'] += 5
```

## Draw the plot fot democracy
```{python}
# Filter the dataset to include only rows where attack counts exceed 1000
gtd_score = gtd_score.loc[gtd_score['attack_count'] > 1000]
point = alt.Chart(gtd_score).mark_circle(size=60, color='steelblue').encode(
    alt.X('avg_score', title='Average Democracy Score (2000-2020)'),
    alt.Y('attack_count', title='Number of Attacks')
).properties(
    width=500,
    height=300,
    title='Number of Terrorist Attacks (2000 - 2020) vs. Democracy Performance'
)
line = point.transform_regression(
    'avg_score', 'attack_count', method='linear'
).mark_line(color='red') 

combined_chart = point + line

final_chart = combined_chart.properties(
    width=500,
    height=300,
    title='Number of Terrorist Attacks vs. Democracy Performance (2000 - 2020)'
).configure_axis(
    grid=True
).configure_title(
    fontSize=12,
    anchor='start',
    color='black'
).configure_mark(
    opacity=0.6
)


final_chart
```

## Draw the plot for economics

```{python}
# Import the GDP data
path = "/Users/wangshiying/Documents/71_Python_Programming_II/DAP2-FINAL/data/"
file_name = "GDP.csv"
df_gdp = pd.read_csv(path + file_name)
df_gdp = df_gdp[df_gdp["Series Name"] == "GDP (current US$)"]

# Convert the GDP values to numeric type
gdp_columns = [col for col in df_gdp.columns if "YR" in col]
for col in gdp_columns:
    df_gdp[col] = pd.to_numeric(df_gdp[col], errors="coerce")

# Calculate the average GDP
df_gdp["average_gdp"] = df_gdp[gdp_columns].mean(axis=1)

# Calculate the amount of attack from GTD data
gtd_count = gtd_clean.groupby("country_txt").agg(
  attack_count = ("country_txt", "size")
).reset_index()
```

```{python}
# Match the names
df_gdp["Country Name"] = df_gdp["Country Name"].replace({
  "Bahamas, The": "Bahamas",
  "Bosnia and Herzegovina": "Bosnia-Herzegovina",
  "Czechia": "Czech Republic",
  "Congo, Dem. Rep.": "Democratic Republic of the Congo",
  "Timor-Leste": "East Timor",
  "Egypt, Arab Rep.": "Egypt",
  "Gambia, The": "Gambia",
  "Hong Kong SAR, China": "Hong Kong",
  "Iran, Islamic Rep.": "Iran",
  "Cote d'Ivoire": "Ivory Coast",
  "Kyrgyz Republic": "Kyrgyzstan",
  "Lao PDR": "Laos",
  "North Macedonia": "Macedonia",
  "Congo, Rep.": "Republic of the Congo",
  "Russian Federation": "Russia",
  "Korea, Rep.": "South Korea",
  "Eswatini": "Swaziland",
  "Syrian Arab Republic": "Syria",
  "Turkiye": "Turkey",
  "Venezuela, RB": "Venezuela",
  "Viet Nam": "Vietnam",
  "West Bank and Gaza": "West Bank and Gaza Strip",
  "Yemen, Rep.": "Yemen"
  })

# Clean countries that no longer exists
gtd_count = gtd_count[gtd_count["country_txt"] != "International"]

# For Yugoslavia
serbia_montenegro_count = gtd_count.loc[gtd_count["country_txt"] == "Serbia-Montenegro", "attack_count"].values[0]
yugoslavia_count = gtd_count.loc[gtd_count["country_txt"] == "Yugoslavia", "attack_count"].values[0]

serbia_count = (serbia_montenegro_count / 2) + (yugoslavia_count / 2)
montenegro_count = (serbia_montenegro_count / 2) + (yugoslavia_count / 2)
gtd_count.loc[gtd_count["country_txt"] == "Serbia", "attack_count"] += serbia_count
gtd_count.loc[gtd_count["country_txt"] == "Montenegro", "attack_count"] += montenegro_count

gtd_count = gtd_count[gtd_count["country_txt"] != "Serbia-Montenegro"]
gtd_count = gtd_count[gtd_count["country_txt"] != "Yugoslavia"]

# For Taiwan
taiwan_count = gtd_count.loc[gtd_count["country_txt"] == "Taiwan", "attack_count"].values[0]
gtd_count.loc[gtd_count["country_txt"] == "China", "attack_count"] += taiwan_count
gtd_count = gtd_count[gtd_count["country_txt"] != "Taiwan"]

# Merge the dataframes
gtd_gdp = gtd_count.merge(df_gdp[["Country Name", "average_gdp"]], left_on="country_txt", right_on="Country Name", how="left")
```

```{python}
# Use log to scale the data
gtd_gdp["log_average_gdp"] = np.log(gtd_gdp["average_gdp"])
gtd_gdp["log_attack_count"] = np.log(gtd_gdp["attack_count"])

# Make the plot
scatter_plot = alt.Chart(gtd_gdp).mark_circle(size=60, opacity=0.6, color="steelblue").encode(
    alt.X("log_average_gdp", title="Log Average GDP ($)", scale=alt.Scale(zero=False)),
    alt.Y("log_attack_count", title="Log Number of Attacks", scale=alt.Scale(zero=True))
).properties(
    width=500,
    height=300,
    title=alt.TitleParams(
        text="Average GDP vs Number of Terrorist Attacks (2000 - 2020)",
        fontSize=12,
        anchor="start",
        color="black"
    )
)

trend_line = scatter_plot.transform_regression("log_average_gdp", "log_attack_count").mark_line(color="red")

scatter_plot + trend_line
```


## Terrorism Groups Analysis
```{python}
# Categorize countries into three regions
SA = ['Afghanistan', 'Bangladesh', 'Bhutan', 'India', 'Pakistan', 
      'Maldives', 'Nepal', 'Sri Lanka']

gtd_clean['region'] = gtd_clean['country_txt'].apply(
    lambda x: 'Iraq' if x == 'Iraq' else 
              'South Asia' if x in SA else 
              'Other Regions'
)

gtd_gnames = gtd_clean[['region', 'gname']]
gtd_gnames = gtd_gnames.groupby(['region', 'gname']).size().reset_index(name='count')
gtd_gnames['Percentage'] = gtd_gnames.groupby('region')['count'].transform(lambda x: x / x.sum())
gtd_gnames.sort_values(by=['region', 'Percentage'], ascending=[True, False], inplace=True)
gtd_gnames = gtd_gnames.groupby('region').head(10)

regions = ['South Asia', 'Iraq', 'Other Regions']
for region in regions:
    data_filtered = gtd_gnames[gtd_gnames['region'] == region]
    chart = alt.Chart(data_filtered).mark_bar().encode(
        x=alt.X(
            'gname:N',
            sort='-y',
            title='Group Names',
            axis=alt.Axis(labelExpr="slice(datum.value, 0, 20)", labelAngle=-45)
        ),
        y=alt.Y('Percentage:Q', title='Proportion'),
        color=alt.Color('gname:N', legend=None, scale=alt.Scale(domain=data_filtered['gname'].unique()))
    ).properties(
        title=f"Groups Responsible for Most Attacks in {region}",
        width=700,
        height=400
    )
    chart.display()
```


## Exploration on the Motive (NLP)

### For Taliban
```{python}
df_gtd_Taliban = gtd_clean[gtd_clean["gname"] == "Taliban"]
motive_texts_Taliban = df_gtd_Taliban["motive"].dropna().tolist()

# Add some meaningless words to the stop words list
custom_stop_words = list(ENGLISH_STOP_WORDS.union({
    "motive", "specific", "attack", "sources", "stated", 
    "claimed", "responsibility", "noted", "carried","unknown", "taliban", "incident", "information", "targeted", "victims", "accused", "victim", "posited", "suspected", "group", "believed"
}))

vectorizer = TfidfVectorizer(stop_words=custom_stop_words, min_df=3)
tfidf_matrix = vectorizer.fit_transform(motive_texts_Taliban)

# Get the key words and corresponding weights
feature_names = vectorizer.get_feature_names_out()
tfidf_scores = tfidf_matrix.sum(axis=0).A1

# Transfer to dataframe
tfidf_df = pd.DataFrame({"Word": feature_names, "Score": tfidf_scores})
tfidf_df = tfidf_df.sort_values(by="Score", ascending=False).head(10)

# Make the plot
alt.Chart(tfidf_df).mark_bar(color="steelblue").encode(
    alt.X("Word", sort="-y", title="Keywords", axis=alt.Axis(labelAngle=-40)),
    alt.Y("Score", title="TF-IDF Score")
).properties(
    title="Top 10 Keywords of Taliban's Motive",
    width=500,
    height=300
).configure_title(
    fontSize=16,
    anchor="middle"
).configure_axis(
    labelFontSize=12,
    titleFontSize=14
)
```

### For ISIL
```{python}
df_gtd_ISIL = gtd_clean[gtd_clean["gname"] == "Islamic State of Iraq and the Levant (ISIL)"]
motive_texts_ISIL = df_gtd_ISIL["motive"].dropna().tolist()

# Add some meaningless words to the stop words list
custom_stop_words = list(ENGLISH_STOP_WORDS.union({
    "motive", "specific", "attack", "sources", "stated", 
    "claimed", "responsibility", "noted", "carried","unknown", "isil", "incident", "information", "targeted", "victims", "accused", "victim", "posited", "suspected", "group", "believed", "area"
}))

vectorizer = TfidfVectorizer(stop_words=custom_stop_words, min_df=3)
tfidf_matrix = vectorizer.fit_transform(motive_texts_ISIL)

# Get the key words and corresponding weights
feature_names = vectorizer.get_feature_names_out()
tfidf_scores = tfidf_matrix.sum(axis=0).A1

# Transfer to dataframe
tfidf_df = pd.DataFrame({"Word": feature_names, "Score": tfidf_scores})
tfidf_df = tfidf_df.sort_values(by="Score", ascending=False).head(10)

# Make the plot
alt.Chart(tfidf_df).mark_bar(color="steelblue").encode(
    alt.X("Word", sort="-y", title="Keywords", axis=alt.Axis(labelAngle=-40)),
    alt.Y("Score", title="TF-IDF Score")
).properties(
    title="Top 10 Keywords of ISIL's Motive",
    width=500,
    height=300
).configure_title(
    fontSize=16,
    anchor="middle"
).configure_axis(
    labelFontSize=12,
    titleFontSize=14
)
```

