---
title: "Final Project"
author: "Sienna Wang, Hengyi Xing"
date: "2024-11-03"
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
output:
  echo: false
  eval: false
---

```{python}
import pandas as pd
import altair as alt
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS
import matplotlib.pyplot as plt
```

# Plot the relationship between the number of attacks and average GDP

```{python}
# Import the GDP data
path = "/Users/wangshiying/Documents/71_Python_Programming_II/DAP2-FINAL/data/"
file_name = "GDP.csv"
df_gdp = pd.read_csv(path + file_name)
df_gdp = df_gdp[df_gdp["Series Name"] == "GDP (current US$)"]

# Convert the GDP values to numeric type
gdp_columns = [col for col in df_gdp.columns if "YR" in col]
for col in gdp_columns:
    df_gdp[col] = pd.to_numeric(df_gdp[col], errors="coerce")

# Calculate the average GDP
df_gdp["average_gdp"] = df_gdp[gdp_columns].mean(axis=1)
```

```{python}
# Import the GTD dataframe
file_name = "globalterrorismdb.csv"
df_gtd = pd.read_csv(path + file_name)

# Filter the dataset to focus on the 21st centry
gtd_clean = df_gtd[['iyear', 'country', 'country_txt', 'gname',
                 'attacktype1', 'attacktype1_txt', 'nkill', 'nwound', 'motive']]
# Focos on the 21st century
gtd_clean = gtd_clean[gtd_clean['iyear'] > 1999]
gtd_clean['nhurt'] = gtd_clean['nkill'] + gtd_clean['nwound']

# Calculate the amount of attack
gtd_count = gtd_clean.groupby("country_txt").agg(
  attack_count = ("country_txt", "size")
).reset_index()
```

```{python}
# Match the names
df_gdp["Country Name"] = df_gdp["Country Name"].replace({
  "Bahamas, The": "Bahamas",
  "Bosnia and Herzegovina": "Bosnia-Herzegovina",
  "Czechia": "Czech Republic",
  "Congo, Dem. Rep.": "Democratic Republic of the Congo",
  "Timor-Leste": "East Timor",
  "Egypt, Arab Rep.": "Egypt",
  "Gambia, The": "Gambia",
  "Hong Kong SAR, China": "Hong Kong",
  "Iran, Islamic Rep.": "Iran",
  "Cote d'Ivoire": "Ivory Coast",
  "Kyrgyz Republic": "Kyrgyzstan",
  "Lao PDR": "Laos",
  "North Macedonia": "Macedonia",
  "Congo, Rep.": "Republic of the Congo",
  "Russian Federation": "Russia",
  "Korea, Rep.": "South Korea",
  "Eswatini": "Swaziland",
  "Syrian Arab Republic": "Syria",
  "Turkiye": "Turkey",
  "Venezuela, RB": "Venezuela",
  "Viet Nam": "Vietnam",
  "West Bank and Gaza": "West Bank and Gaza Strip",
  "Yemen, Rep.": "Yemen"
  })

# Clean countries that no longer exists
gtd_count = gtd_count[gtd_count["country_txt"] != "International"]

# For Yugoslavia
serbia_montenegro_count = gtd_count.loc[gtd_count["country_txt"] == "Serbia-Montenegro", "attack_count"].values[0]
yugoslavia_count = gtd_count.loc[gtd_count["country_txt"] == "Yugoslavia", "attack_count"].values[0]

serbia_count = (serbia_montenegro_count / 2) + (yugoslavia_count / 2)
montenegro_count = (serbia_montenegro_count / 2) + (yugoslavia_count / 2)
gtd_count.loc[gtd_count["country_txt"] == "Serbia", "attack_count"] += serbia_count
gtd_count.loc[gtd_count["country_txt"] == "Montenegro", "attack_count"] += montenegro_count

gtd_count = gtd_count[gtd_count["country_txt"] != "Serbia-Montenegro"]
gtd_count = gtd_count[gtd_count["country_txt"] != "Yugoslavia"]

# For Taiwan
taiwan_count = gtd_count.loc[gtd_count["country_txt"] == "Taiwan", "attack_count"].values[0]
gtd_count.loc[gtd_count["country_txt"] == "China", "attack_count"] += taiwan_count
gtd_count = gtd_count[gtd_count["country_txt"] != "Taiwan"]

# Merge the dataframes
gtd_gdp = gtd_count.merge(df_gdp[["Country Name", "average_gdp"]], left_on="country_txt", right_on="Country Name", how="left")
```

```{python}
# Use log to scale the data
gtd_gdp["log_average_gdp"] = np.log(gtd_gdp["average_gdp"])
gtd_gdp["log_attack_count"] = np.log(gtd_gdp["attack_count"])

# Make the plot
scatter_plot = alt.Chart(gtd_gdp).mark_circle(size=60, opacity=0.6, color="steelblue").encode(
    alt.X("log_average_gdp", title="Log Average GDP ($)", scale=alt.Scale(zero=False)),
    alt.Y("log_attack_count", title="Log Number of Attacks", scale=alt.Scale(zero=True))
).properties(
    width=500,
    height=300,
    title=alt.TitleParams(
        text="Average GDP vs Number of Terrorist Attacks (2000 - 2020)",
        fontSize=12,
        anchor="start",
        color="black"
    )
)

trend_line = scatter_plot.transform_regression("log_average_gdp", "log_attack_count").mark_line(color="red")

scatter_plot + trend_line
```


# Exploration on the Motive (NLP)

## For Taliban
```{python}
df_gtd_Taliban = gtd_clean[gtd_clean["gname"] == "Taliban"]
motive_texts_Taliban = df_gtd_Taliban["motive"].dropna().tolist()

# Add some meaningless words to the stop words list
custom_stop_words = list(ENGLISH_STOP_WORDS.union({
    "motive", "specific", "attack", "sources", "stated", 
    "claimed", "responsibility", "noted", "carried","unknown", "taliban", "incident", "information", "targeted", "victims", "accused", "victim", "posited", "suspected", "group", "believed"
}))

vectorizer = TfidfVectorizer(stop_words=custom_stop_words, min_df=3)
tfidf_matrix = vectorizer.fit_transform(motive_texts_Taliban)

# Get the key words and corresponding weights
feature_names = vectorizer.get_feature_names_out()
tfidf_scores = tfidf_matrix.sum(axis=0).A1

# Transfer to dataframe
tfidf_df = pd.DataFrame({"Word": feature_names, "Score": tfidf_scores})
tfidf_df = tfidf_df.sort_values(by="Score", ascending=False).head(10)

# Make the plot
alt.Chart(tfidf_df).mark_bar(color="steelblue").encode(
    alt.X("Word", sort="-y", title="Keywords", axis=alt.Axis(labelAngle=-40)),
    alt.Y("Score", title="TF-IDF Score")
).properties(
    title="Top 10 Keywords of Taliban's Motive",
    width=500,
    height=300
).configure_title(
    fontSize=16,
    anchor="middle"
).configure_axis(
    labelFontSize=12,
    titleFontSize=14
)
```


```{python}
df_gtd_ISIL = gtd_clean[gtd_clean["gname"] == "Islamic State of Iraq and the Levant (ISIL)"]
motive_texts_ISIL = df_gtd_ISIL["motive"].dropna().tolist()

# Add some meaningless words to the stop words list
custom_stop_words = list(ENGLISH_STOP_WORDS.union({
    "motive", "specific", "attack", "sources", "stated", 
    "claimed", "responsibility", "noted", "carried","unknown", "isil", "incident", "information", "targeted", "victims", "accused", "victim", "posited", "suspected", "group", "believed", "area"
}))

vectorizer = TfidfVectorizer(stop_words=custom_stop_words, min_df=3)
tfidf_matrix = vectorizer.fit_transform(motive_texts_ISIL)

# Get the key words and corresponding weights
feature_names = vectorizer.get_feature_names_out()
tfidf_scores = tfidf_matrix.sum(axis=0).A1

# Transfer to dataframe
tfidf_df = pd.DataFrame({"Word": feature_names, "Score": tfidf_scores})
tfidf_df = tfidf_df.sort_values(by="Score", ascending=False).head(10)

# Make the plot
alt.Chart(tfidf_df).mark_bar(color="steelblue").encode(
    alt.X("Word", sort="-y", title="Keywords", axis=alt.Axis(labelAngle=-40)),
    alt.Y("Score", title="TF-IDF Score")
).properties(
    title="Top 10 Keywords of ISIL's Motive",
    width=500,
    height=300
).configure_title(
    fontSize=16,
    anchor="middle"
).configure_axis(
    labelFontSize=12,
    titleFontSize=14
)
```